{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proof of Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Number of Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = requests.get(\"https://clinicaltrials.gov/api/v2/stats/size\")\n",
    "total_studies = json.loads(size.content)['totalStudies']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather All Studies POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 7/473 [00:06<07:45,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/473 [00:07<07:16,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/473 [00:08<07:25,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/473 [00:09<07:02,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/473 [00:10<07:15,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 12/473 [00:10<06:52,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 13/473 [00:11<06:32,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 14/473 [00:12<07:03,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/473 [00:13<06:51,  1.11it/s]"
     ]
    }
   ],
   "source": [
    "aggregated_studies = []\n",
    "nextPage = None\n",
    "\n",
    "request_delay = 1 / 3  #  <= 3 Requests per second\n",
    "\n",
    "for _ in tqdm(range(ceil(total_studies/1000))):\n",
    "    try:\n",
    "        payload = {'format': 'json', 'pageSize': '1000', 'pageToken' : f'{nextPage}'} if nextPage else {'format': 'json', 'pageSize': '1000'}\n",
    "        data = requests.get(\"https://clinicaltrials.gov/api/v2/studies\", params=payload, timeout=5.0)\n",
    "        studies = data.json()\n",
    "\n",
    "        aggregated_studies.extend(studies['studies'])\n",
    "\n",
    "        # The last page does not have a nextPageToken field\n",
    "        if 'nextPageToken' not in studies:\n",
    "            break\n",
    "\n",
    "        nextPage = studies['nextPageToken']\n",
    "\n",
    "        time.sleep(request_delay)\n",
    "    except:\n",
    "        print('Page Token:', nextPage)\n",
    "        print('Payload:', payload)\n",
    "        print('# Aggregated Studies:', len(aggregated_studies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Expected Studies:', total_studies)\n",
    "print('Gathered Studies:', len(aggregated_studies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version / Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Time Stamp: 2023-11-08\n"
     ]
    }
   ],
   "source": [
    "version = requests.get(\"https://clinicaltrials.gov/api/v2/version\").json()\n",
    "print('Data Time Stamp:', version['dataTimestamp'].split('T')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumper POC\n",
    "\n",
    "Formatting code similar to how it would look in a dumper (HTTPDumper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 473/473 [04:29<00:00,  1.75it/s]\n"
     ]
    }
   ],
   "source": [
    "API_PAGE = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "PAGE_SIZE=1000\n",
    "\n",
    "ids = []\n",
    "pageTokens = []\n",
    "\n",
    "total_pages = (total_studies + PAGE_SIZE - 1) // PAGE_SIZE  # Calculate total pages\n",
    "\n",
    "nextPage = None\n",
    "for p in tqdm(range(1, total_pages + 1)):\n",
    "    if nextPage:\n",
    "        doc = requests.get(API_PAGE + f\"?fields=NCTId&pageSize={PAGE_SIZE}&pageToken={nextPage}\").json()\n",
    "    else:\n",
    "        doc = requests.get(API_PAGE + f\"?fields=NCTId&pageSize={PAGE_SIZE}\").json()\n",
    "\n",
    "    if 'nextPageToken' in doc:\n",
    "        nextPage = doc['nextPageToken']\n",
    "        pageTokens.append(nextPage)\n",
    "\n",
    "    for study in doc['studies']:\n",
    "        ids.append(study['protocolSection']['identificationModule']['nctId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser / Uploader POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 473/473 [02:22<00:00,  3.32it/s]\n"
     ]
    }
   ],
   "source": [
    "API_PAGE = \"https://clinicaltrials.gov/api/v2/studies\"\n",
    "PAGE_SIZE=1000\n",
    "\n",
    "ids = []\n",
    "pageTokens = []\n",
    "\n",
    "total_pages = (total_studies + PAGE_SIZE - 1) // PAGE_SIZE  # Calculate total pages\n",
    "\n",
    "nextPage = None\n",
    "for p in tqdm(range(1, total_pages + 1)):\n",
    "    if nextPage:\n",
    "        res = requests.get(API_PAGE + f\"?fields=NCTId&pageSize={PAGE_SIZE}&pageToken={nextPage}\", stream=True)\n",
    "    else:\n",
    "        res = requests.get(API_PAGE + f\"?fields=NCTId&pageSize={PAGE_SIZE}\", stream=True)\n",
    "\n",
    "    doc = res.json()\n",
    "\n",
    "    if 'nextPageToken' in doc:\n",
    "        nextPage = doc['nextPageToken']\n",
    "        pageTokens.append(nextPage)\n",
    "\n",
    "    fout = open(f\"json_data/{p}.json\", \"wb\")\n",
    "    for chunk in res.iter_content(chunk_size=512 * 1024):\n",
    "        if chunk:\n",
    "            fout.write(chunk)\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 473/473 [00:01<00:00, 361.26it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from biothings.utils.dataload import unlist, dict_sweep\n",
    "\n",
    "data_folder = \"json_data\"\n",
    "for infile in tqdm(glob.glob(os.path.join(data_folder,\"*.json\"))):\n",
    "    doc = json.load(open(infile))\n",
    "\n",
    "    studies = doc[\"studies\"]\n",
    "\n",
    "    for study in studies:\n",
    "        print(study[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
